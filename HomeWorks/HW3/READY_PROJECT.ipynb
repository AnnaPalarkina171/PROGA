{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import requests\n",
    "import html\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "links = []\n",
    "\n",
    "#краулер ищет ссылки на статьи по страницам (171) \n",
    "def articles_links():\n",
    "    for i in range(10):   #их тут всего 171, но я не буду брать все, слишком тяжело и все падает\n",
    "        try:\n",
    "            url = 'http://pav-edin23.ru/category/obshhestvo/page/' + str(i) + '/'\n",
    "            r = requests.get(url)\n",
    "            text = r.text\n",
    "            soup = BeautifulSoup(text, 'lxml')\n",
    "        except:\n",
    "            print('Error at: ', url)\n",
    "        divs = soup.findAll('div', {'class': 'entry-thumb'})\n",
    "        for div in divs:\n",
    "            for anchor in div.find_all('a'):\n",
    "                a = anchor.get('href')\n",
    "                links.append(a)\n",
    "\n",
    "#Создаем каталог plain + mystem-xml\n",
    "def katalog():\n",
    "    path = os.getcwd()\n",
    "    h_row = ['path', 'author', 'header', 'created', 'sphere', 'topic', 'style', 'audience_age', 'audience_level', \n",
    "             'audience_size', 'source', 'publication', 'publ_year', 'medium', 'country', 'region', 'language']\n",
    "    if not os.path.exists(path + '\\\\newspaper'):\n",
    "                os.makedirs(path + '\\\\newspaper')\n",
    "    meta_name = path + '\\\\newspaper\\\\metadata.csv'\n",
    "    with open( meta_name,'w', encoding='utf-8') as f:\n",
    "        header_row = '\\t'.join(h_row)\n",
    "        f.write(header_row)\n",
    "        f.write('\\n')                                                         #создали заголовки мета-таблицы\n",
    "       \n",
    "    regTag = re.compile('<.*?>', re.DOTALL)                                     # это рег. выражение находит все тэги\n",
    "    regScript = re.compile('<script>.*?</script>', re.DOTALL)                   # все скрипты\n",
    "    regComment = re.compile('<!--.*?-->', re.DOTALL)                            # все комментарии\n",
    "    regNum = re.compile(r'[-+]?(?:\\d+(?:\\.\\d*)?|\\.\\d+)(?:[eE][-+]?\\d+)?')       #все цифровые значения\n",
    "    regLang = re.compile(r'[^ЁА-Яёа-я ]')                                       #нерусские слова     \n",
    "    for link in links:\n",
    "        r = requests.get(link)\n",
    "        text = r.text\n",
    "        soup = BeautifulSoup(text, 'lxml')\n",
    "        divs = soup.findAll('div', {'class': 'entry entry-content'})\n",
    "        for div in divs:\n",
    "            p = div.findAll('p')\n",
    "            clean_p = regScript.sub(\"\", str(p))\n",
    "            clean_p = regComment.sub(\"\", clean_p)\n",
    "            clean_p = regTag.sub(\"\", clean_p)\n",
    "            clean_p = html.unescape(clean_p)\n",
    "            clean_p = regNum.sub(\"\",clean_p)\n",
    "            clean_p = regLang.sub(\"\", clean_p)                                  #Это отчищенный и готовый текст статьи\n",
    "            title = re.findall(r'<h1 class=\"entry-title\">(.*?)</h1>', text)\n",
    "            data = re.compile(r'[\\d{4}/\\d{2}/\\d{2}]')\n",
    "            data = data.findall(link)\n",
    "            year = ''.join(data[5:9])\n",
    "            month = ''.join(data[10:12])\n",
    "            day = ''.join(data[13:15])\n",
    "            name = link.split('/')[-2]\n",
    "            \n",
    "            if not os.path.exists(path + '\\\\newspaper' + '\\\\plain'):\n",
    "                os.makedirs(path + '\\\\newspaper' + '\\\\plain')\n",
    "            if not os.path.exists(path + '\\\\newspaper' + '\\\\plain\\\\' + year ):\n",
    "                os.makedirs(path + '\\\\newspaper' + '\\\\plain\\\\'  + year)\n",
    "            if not os.path.exists(path + '\\\\newspaper'+ '\\\\plain\\\\' + year + '\\\\' + month):\n",
    "                os.makedirs(path + '\\\\newspaper'+ '\\\\plain\\\\' + year + '\\\\' + month)\n",
    "            if not os.path.exists(path + '\\\\newspaper'+ '\\\\plain\\\\' + year + '\\\\' + month + '\\\\' + day):\n",
    "                os.makedirs(path + '\\\\newspaper'+ '\\\\plain\\\\' + year + '\\\\' + month+ '\\\\' + day)\n",
    "            txt_name = path + '\\\\newspaper\\\\plain\\\\' + year + '\\\\' + month+ '\\\\' + day + '\\\\' + name + '.txt'\n",
    "            \n",
    "            path_ = txt_name\n",
    "            author = \"none\"\n",
    "            header = title[0]\n",
    "            created = day + '.' + month + '.' + year\n",
    "            sphere = \"публицистика\"\n",
    "            topic = 'общество'\n",
    "            style = \"нейтральный\"\n",
    "            audience_age = \"н-возраст\"\n",
    "            audience_level = 'н-уровень'\n",
    "            audience_size = 'районная'\n",
    "            source = link\n",
    "            publication = 'Единство'\n",
    "            publ_year = year\n",
    "            medium = \"газета\"\n",
    "            country =  \"Россия\"\n",
    "            region = 'Павловский район'\n",
    "            language = \"ru\"\n",
    "            \n",
    "            with open(txt_name,'w', encoding='utf-8') as f:               \n",
    "                au = '@au ' + author + '\\n'                      #это все потом очень сильно мешается\n",
    "                ti = '@ti ' + header + '\\n'                     #но нет времени их убирать\n",
    "                da = '@da ' + created + '\\n'\n",
    "                top = '@topic ' + topic + '\\n'\n",
    "                ur = '@url' + link + '\\n'\n",
    "                f.write(au)\n",
    "                f.write(ti)\n",
    "                f.write(da)\n",
    "                f.write(top)\n",
    "                f.write(ur)\n",
    "                f.write(clean_p)                                      #создали необработанные тексты статей\n",
    "                \n",
    "                \n",
    "            row = [path_, author, header, created, sphere, topic, style, audience_age, audience_level, audience_size, source,\n",
    "                   publication, publ_year, medium, country, region, language]\n",
    "            new_row = '\\t'.join(row)\n",
    "            with open( meta_name,'a', encoding='utf-8') as f:\n",
    "                f.write(new_row)\n",
    "                f.write('\\n')\n",
    "                \n",
    "            if not os.path.exists(path + '\\\\newspaper\\\\mystem-xml'):\n",
    "                os.makedirs(path + '\\\\newspaper\\\\mystem-xml')\n",
    "            if not os.path.exists(path + '\\\\newspaper\\\\mystem-xml\\\\' + year ):\n",
    "                os.makedirs(path + '\\\\newspaper\\\\mystem-xml\\\\'  + year)\n",
    "            if not os.path.exists(path + '\\\\newspaper\\\\mystem-xml\\\\' + year + '\\\\' + month):\n",
    "                os.makedirs(path + '\\\\newspaper\\\\mystem-xml\\\\' + year + '\\\\' + month)\n",
    "            if not os.path.exists(path + '\\\\newspaper\\\\mystem-xml\\\\' + year + '\\\\' + month + '\\\\' + day):\n",
    "                os.makedirs(path + '\\\\newspaper\\\\mystem-xml\\\\' + year + '\\\\' + month+ '\\\\' + day)  \n",
    "            xml_name = path + '\\\\newspaper\\\\mystem-xml\\\\' + year + '\\\\' + month+ '\\\\' + day + '\\\\' + name + '.xml'\n",
    "            \n",
    "            #создаем обработанные тексты статей\n",
    "            os.system(r'C:\\\\Users\\\\User\\\\Desktop\\\\mystem.exe -cdgin --format xml --eng-gr {} {}'.format(txt_name,xml_name))\n",
    "            \n",
    "            if not os.path.exists(path + '\\\\newspaper\\\\mystem-plain'):\n",
    "                os.makedirs(path + '\\\\newspaper\\\\mystem-plain')\n",
    "            if not os.path.exists(path + '\\\\newspaper\\\\mystem-plain\\\\' + year ):\n",
    "                os.makedirs(path + '\\\\newspaper\\\\mystem-plain\\\\'  + year)\n",
    "            if not os.path.exists(path + '\\\\newspaper\\\\mystem-plain\\\\' + year + '\\\\' + month):\n",
    "                os.makedirs(path + '\\\\newspaper\\\\mystem-plain\\\\' + year + '\\\\' + month)\n",
    "            if not os.path.exists(path + '\\\\newspaper\\\\mystem-plain\\\\' + year + '\\\\' + month + '\\\\' + day):\n",
    "                os.makedirs(path + '\\\\newspaper\\\\mystem-plain\\\\' + year + '\\\\' + month+ '\\\\' + day)  \n",
    "            plain_name = path + '\\\\newspaper\\\\mystem-plain\\\\' + year + '\\\\' + month+ '\\\\' + day + '\\\\' + name + '.txt'\n",
    "            \n",
    "            os.system(r'C:\\\\Users\\\\User\\\\Desktop\\\\mystem.exe -cdgin  --eng-gr {} {}'.format(txt_name,plain_name))\n",
    "            \n",
    "\n",
    "def main():\n",
    "    articles_links()\n",
    "    katalog()\n",
    "main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
